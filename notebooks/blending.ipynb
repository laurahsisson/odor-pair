{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4412a8-233a-44b3-ba6e-6d5cb89bd6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9884392-3d20-4227-a8dc-5c8ab4c6b27d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 109 notes in blends.\n",
      "Canonized down to 77 notes in blends.\n",
      "\n",
      "Found 496 notes for single molecules.\n",
      "Not canonizing single notes\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import tqdm\n",
    "import torchmetrics\n",
    "import graph.utils\n",
    "import single.utils\n",
    "\n",
    "import numpy as np\n",
    "import analysis.fingerprint\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import warnings\n",
    "\n",
    "with open(\"dataset/full.json\") as f:\n",
    "    full_data = json.load(f)\n",
    "\n",
    "all_blend_notes = set()\n",
    "all_single_notes = set()\n",
    "for d in full_data:\n",
    "    all_blend_notes.update(d[\"blend_notes\"])\n",
    "    all_single_notes.update(d[\"mol1_notes\"])\n",
    "    all_single_notes.update(d[\"mol2_notes\"])\n",
    "\n",
    "# Convert to list so indexing is faster.\n",
    "print(f\"Found {len(all_blend_notes)} notes in blends.\")\n",
    "all_blend_notes = list(graph.utils.canonize(all_blend_notes))\n",
    "print(f\"Canonized down to {len(all_blend_notes)} notes in blends.\")\n",
    "print()\n",
    "print(f\"Found {len(all_single_notes)} notes for single molecules.\")\n",
    "print(\"Not canonizing single notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4852ba-a8e9-4c6e-8891-ba23be940622",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "model = INSTRUCTOR('hkunlp/instructor-large')\n",
    "instruction = \"Represent the Odor descriptor for canonicalization:\"\n",
    "blend_embeddings = model.encode([[instruction, n] for n in all_blend_notes])\n",
    "single_embeddings = model.encode([[instruction, n] for n in all_single_notes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2a7eb0-4e45-40d2-ac93-d87eb87c96c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import scipy\n",
    "sims = dict()\n",
    "for i, note in enumerate(all_single_notes):\n",
    "    sims[note] = collections.Counter()\n",
    "    for j, other in enumerate(all_blend_notes):\n",
    "        sims[note][other] = (1-scipy.spatial.distance.cosine(single_embeddings[i],blend_embeddings[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146471fb-835d-4bb6-9260-1b19b02c5642",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pine'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canonize = {n:cntr.most_common(1)[0][0] for n,cntr in sims.items()}\n",
    "canonize[\"pine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d68cd2f0-fa9b-45ce-a14b-c1dbb9e49812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def canonize_notes(notes):\n",
    "    return [canonize[n] for n in notes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba0dfcc-13f5-4d1e-8f87-93f13798b240",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 166814/166814 [00:11<00:00, 14672.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981\n"
     ]
    }
   ],
   "source": [
    "ys = []\n",
    "xs = []\n",
    "empty = 0\n",
    "for d in tqdm.tqdm(full_data):\n",
    "    blnd = graph.utils.canonize(d[\"blend_notes\"])\n",
    "    if len(blnd) == 0:\n",
    "        empty+=1\n",
    "        continue\n",
    "    ys.append(graph.utils.multi_hot(blnd))\n",
    "    assert ys[-1].sum() == len(blnd)\n",
    "\n",
    "    n1 = canonize_notes(d[\"mol1_notes\"])\n",
    "    n2 = canonize_notes(d[\"mol2_notes\"])\n",
    "    xs.append(torch.concat([graph.utils.multi_hot(n1),graph.utils.multi_hot(n2)]))\n",
    "    assert xs[-1].sum() == len(n1+n2)\n",
    "\n",
    "print(empty)\n",
    "ys = torch.stack(ys).int()\n",
    "xs = torch.stack(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "118999b4-4c17-4b9b-9bd7-0db1f8fafba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "class LogitRegression(sklearn.linear_model.RidgeCV):\n",
    "    EPS = 1e-5\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def _clip01(self,arr):\n",
    "        return np.asarray(arr).clip(self.EPS,1-self.EPS)\n",
    "\n",
    "    def fit(self, x, p):\n",
    "        p = self._clip01(p)\n",
    "        y = scipy.special.logit(p)\n",
    "        return super().fit(x, y)\n",
    "    \n",
    "    def _is_multitask(self):\n",
    "        return True\n",
    "\n",
    "    def predict(self, x):\n",
    "        y = super().predict(x)\n",
    "        return scipy.special.expit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcc4e7f1-6d77-4314-9324-ef9948ffce1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:torch.Size([124374, 154])->torch.Size([124374, 77])\n",
      "Test:torch.Size([41459, 154])->torch.Size([41459, 77])\n",
      "AUROC for model from blend -> blend: 0.96860343\n",
      "[('thujonic', 0.9994554), ('mossy', 0.9993726), ('fresh', 0.99932647), ('sour', 0.9983013), ('solvent', 0.99821025), ('mustard', 0.9977543), ('licorice', 0.9977073), ('fusel', 0.9972534), ('cheesy', 0.99660116), ('coumarinic', 0.99656326), ('tonka', 0.9958565), ('mentholic', 0.9955012), ('clean', 0.99515915), ('marine', 0.9950988), ('acidic', 0.9947129), ('orris', 0.994557), ('vanilla', 0.99437743), ('animal', 0.9942964), ('chocolate', 0.99420017), ('coconut', 0.99377936), ('musk', 0.99372214), ('rummy', 0.9936969), ('jammy', 0.9935465), ('roasted', 0.99275625), ('anise', 0.9922807), ('alliaceous', 0.9920552), ('meaty', 0.99185413), ('alcoholic', 0.99171835), ('cocoa', 0.9909704), ('amber', 0.9879905), ('caramellic', 0.98621315), ('honey', 0.9851037), ('berry', 0.98485374), ('buttery', 0.9820218), ('camphoreous', 0.98147976), ('estery', 0.9793539), ('aldehydic', 0.978346), ('soapy', 0.97730154), ('phenolic', 0.9759244), ('brown', 0.9758157), ('coffee', 0.9739259), ('oily', 0.97317845), ('sulfurous', 0.9730988), ('minty', 0.97249126), ('medicinal', 0.9723441), ('vegetable', 0.97020155), ('bready', 0.96875554), ('fungal', 0.9687202), ('aromatic', 0.96787757), ('sweet', 0.96734244), ('cooling', 0.9660903), ('creamy', 0.96468437), ('woody', 0.9643526), ('balsamic', 0.96347505), ('winey', 0.9625201), ('dairy', 0.96084696), ('tropical', 0.95978904), ('melon', 0.9588825), ('pine', 0.9588038), ('nutty', 0.958316), ('ethereal', 0.9541428), ('earthy', 0.951451), ('chemical', 0.9510576), ('bitter', 0.94500065), ('spicy', 0.94495994), ('fermented', 0.93538606), ('citrus', 0.9323081), ('powdery', 0.927118), ('burnt', 0.92002946), ('musty', 0.9166236), ('fatty', 0.90722036), ('waxy', 0.90327024), ('herbal', 0.901281), ('onion', 0.89999485), ('floral', 0.8922065), ('fruity', 0.87998116), ('green', 0.8396622)]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", \".*samples in target*\")\n",
    "auroc = torchmetrics.classification.MultilabelAUROC(ys.shape[1],average=None)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(xs, ys)\n",
    "print(f\"Train:{X_train.shape}->{y_train.shape}\")\n",
    "print(f\"Test:{X_test.shape}->{y_test.shape}\")\n",
    "# Try going bak to RidgeCV with alpha=alphas=[1e-3, 1e-2, 1e-1, 1]\n",
    "lgr = LogitRegression().fit(X_train,y_train)\n",
    "test_pred = torch.from_numpy(lgr.predict(X_test))\n",
    "scores = auroc(test_pred,y_test).numpy()\n",
    "print(\"AUROC for model from blend -> blend:\",np.mean(scores))\n",
    "idcs = np.flip(np.argsort(scores))\n",
    "print(list(zip(np.array(all_blend_notes)[idcs],scores[idcs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "436ee4a8-76c4-4f30-a7c2-6fd85a8ed7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To have alpha>.9, we can do blends of size 3.30.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(f\"To have alpha>.9, we can do blends of size {math.log(.9,np.mean(scores)):.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe2eae8b-f380-488b-9b48-be7931059475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "note_translator = LogitRegression().fit(single_embeddings.T,blend_embeddings.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8569818-1cc9-4634-946d-787611fb2fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 166814/166814 [00:23<00:00, 7129.51it/s]\n"
     ]
    }
   ],
   "source": [
    "ys = []\n",
    "n1s = []\n",
    "n2s = []\n",
    "empty = 0\n",
    "for d in tqdm.tqdm(full_data):\n",
    "    blnd = graph.utils.canonize(d[\"blend_notes\"])\n",
    "    if len(blnd) == 0:\n",
    "        empty+=1\n",
    "        continue\n",
    "    ys.append(graph.utils.multi_hot(blnd))\n",
    "    assert ys[-1].sum() == len(blnd)\n",
    "\n",
    "    n1s.append(graph.utils.multi_hot(d[\"mol1_notes\"],underyling_list=list(all_single_notes)))\n",
    "    n2s.append(graph.utils.multi_hot(d[\"mol2_notes\"],underyling_list=list(all_single_notes)))\n",
    "\n",
    "n1s = note_translator.predict(n1s)\n",
    "n2s = note_translator.predict(n2s)\n",
    "ys = torch.stack(ys).int()\n",
    "xs = np.concatenate([n1s,n2s],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56b7ce2a-2989-4f62-b9b7-7445a886ac27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:(124374, 154)->torch.Size([124374, 77])\n",
      "Test:(41459, 154)->torch.Size([41459, 77])\n",
      "AUROC for model from blend -> blend: 0.9641541\n",
      "[('fresh', 0.99982446), ('fusel', 0.9998221), ('alcoholic', 0.99954265), ('sour', 0.9995146), ('thujonic', 0.9992993), ('pine', 0.9990592), ('solvent', 0.9982702), ('acidic', 0.9982362), ('mentholic', 0.99767286), ('orris', 0.9975846), ('meaty', 0.99745953), ('vanilla', 0.9971478), ('coumarinic', 0.99686146), ('cheesy', 0.99678963), ('tonka', 0.9955317), ('roasted', 0.99455297), ('camphoreous', 0.99433887), ('jammy', 0.9939801), ('clean', 0.9936921), ('mustard', 0.99341905), ('animal', 0.9933197), ('musk', 0.9922268), ('coconut', 0.9910068), ('mossy', 0.98904395), ('buttery', 0.98865634), ('phenolic', 0.9872745), ('dairy', 0.98716354), ('sulfurous', 0.98709965), ('fungal', 0.9869147), ('vegetable', 0.98689055), ('amber', 0.9854644), ('chocolate', 0.98477143), ('anise', 0.9833919), ('coffee', 0.9831932), ('onion', 0.98213166), ('cocoa', 0.9813953), ('rummy', 0.97828436), ('caramellic', 0.97820926), ('alliaceous', 0.9782034), ('bready', 0.97456336), ('licorice', 0.97299814), ('creamy', 0.9718998), ('marine', 0.9709565), ('bitter', 0.97082263), ('minty', 0.9701557), ('soapy', 0.96742445), ('oily', 0.96721965), ('nutty', 0.9652161), ('berry', 0.9636035), ('honey', 0.9626245), ('aldehydic', 0.961709), ('tropical', 0.95807666), ('ethereal', 0.95720834), ('earthy', 0.9570794), ('woody', 0.95206064), ('balsamic', 0.9503951), ('estery', 0.95020515), ('aromatic', 0.94857115), ('brown', 0.94414973), ('chemical', 0.9436678), ('musty', 0.94177717), ('spicy', 0.93866295), ('cooling', 0.93847734), ('burnt', 0.9381994), ('winey', 0.9366929), ('medicinal', 0.93603057), ('melon', 0.92806494), ('fermented', 0.9274788), ('fatty', 0.9174048), ('herbal', 0.91726303), ('sweet', 0.9137145), ('citrus', 0.9104271), ('waxy', 0.9040661), ('floral', 0.85941696), ('fruity', 0.8574252), ('green', 0.8214795), ('powdery', 0.80544573)]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", \".*samples in target*\")\n",
    "auroc = torchmetrics.classification.MultilabelAUROC(ys.shape[1],average=None)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(xs, ys)\n",
    "print(f\"Train:{X_train.shape}->{y_train.shape}\")\n",
    "print(f\"Test:{X_test.shape}->{y_test.shape}\")\n",
    "# Try going bak to RidgeCV with alpha=alphas=[1e-3, 1e-2, 1e-1, 1]\n",
    "lgr = LogitRegression().fit(X_train,y_train)\n",
    "test_pred = torch.from_numpy(lgr.predict(X_test))\n",
    "scores = auroc(test_pred,y_test).numpy()\n",
    "print(\"AUROC for model from blend -> blend:\",np.mean(scores))\n",
    "idcs = np.flip(np.argsort(scores))\n",
    "print(list(zip(np.array(all_blend_notes)[idcs],scores[idcs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0670bfe-87fa-4564-880d-3f1ed98465e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 166814/166814 [00:39<00:00, 4274.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import analysis.fingerprint\n",
    "mfp = analysis.fingerprint.make_mfpgen()\n",
    "\n",
    "ys = []\n",
    "n1s = []\n",
    "fp1s = []\n",
    "n2s = []\n",
    "fp2s = []\n",
    "empty = 0\n",
    "for d in tqdm.tqdm(full_data):\n",
    "    try:\n",
    "        blnd = graph.utils.canonize(d[\"blend_notes\"])\n",
    "        if len(blnd) == 0:\n",
    "            empty+=1\n",
    "            continue\n",
    "\n",
    "        fp1 = analysis.fingerprint.smiles_to_embed(mfp,d[\"mol1\"])\n",
    "        mt1 = graph.utils.multi_hot(d[\"mol1_notes\"],underyling_list=list(all_single_notes))\n",
    "        \n",
    "        fp2 = analysis.fingerprint.smiles_to_embed(mfp,d[\"mol2\"])\n",
    "        mt2 = graph.utils.multi_hot(d[\"mol2_notes\"],underyling_list=list(all_single_notes))\n",
    "    except TypeError:\n",
    "        continue\n",
    "        \n",
    "    ys.append(graph.utils.multi_hot(blnd))\n",
    "    assert ys[-1].sum() == len(blnd)\n",
    "    n1s.append(mt1)\n",
    "    n2s.append(mt2)\n",
    "    fp1s.append(fp1)\n",
    "    fp2s.append(fp2)\n",
    "\n",
    "n1s = note_translator.predict(n1s)\n",
    "n2s = note_translator.predict(n2s)\n",
    "ys = torch.stack(ys).int()\n",
    "xs = np.concatenate([n1s,n2s],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82c53f72-7df4-46d8-aec0-5b9d2b2b351a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:(124316, 154)->torch.Size([124316, 77])\n",
      "Test:(41439, 154)->torch.Size([41439, 77])\n",
      "AUROC for model from blend -> blend: 0.9638883\n",
      "[('thujonic', 0.9998699), ('fusel', 0.99958193), ('licorice', 0.99910927), ('solvent', 0.9988805), ('clean', 0.99861366), ('pine', 0.9985922), ('mustard', 0.99843836), ('meaty', 0.99795306), ('acidic', 0.9975142), ('cheesy', 0.99748904), ('sour', 0.99734473), ('vanilla', 0.9973091), ('alcoholic', 0.9957749), ('tonka', 0.99574125), ('mentholic', 0.9955141), ('roasted', 0.9941913), ('camphoreous', 0.9937157), ('coconut', 0.9935384), ('orris', 0.9926795), ('coumarinic', 0.99248725), ('mossy', 0.99228007), ('jammy', 0.9920994), ('cocoa', 0.991244), ('fresh', 0.99088013), ('phenolic', 0.990392), ('animal', 0.98994017), ('musk', 0.9890408), ('coffee', 0.98681813), ('marine', 0.98646426), ('sulfurous', 0.9859447), ('rummy', 0.985246), ('anise', 0.9844454), ('buttery', 0.984146), ('amber', 0.98326427), ('vegetable', 0.98245746), ('chocolate', 0.9821696), ('onion', 0.981478), ('fungal', 0.9810452), ('alliaceous', 0.9787116), ('dairy', 0.9783387), ('caramellic', 0.9769916), ('bready', 0.97681725), ('soapy', 0.9730971), ('creamy', 0.97210777), ('nutty', 0.9688259), ('aldehydic', 0.9652503), ('minty', 0.96465147), ('honey', 0.9644886), ('earthy', 0.9620589), ('berry', 0.9616468), ('chemical', 0.9611731), ('bitter', 0.9561676), ('aromatic', 0.95605147), ('oily', 0.9533289), ('estery', 0.9530456), ('cooling', 0.9523087), ('ethereal', 0.9522581), ('balsamic', 0.95015574), ('medicinal', 0.94992983), ('woody', 0.9450251), ('brown', 0.94453406), ('tropical', 0.9399264), ('burnt', 0.9365624), ('spicy', 0.93650603), ('fermented', 0.93593377), ('winey', 0.9348337), ('melon', 0.9304867), ('musty', 0.92202723), ('herbal', 0.9190762), ('fatty', 0.9164176), ('citrus', 0.90401196), ('waxy', 0.90344614), ('sweet', 0.89312875), ('floral', 0.8611748), ('fruity', 0.8580246), ('green', 0.8207886), ('powdery', 0.79640114)]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", \".*samples in target*\")\n",
    "auroc = torchmetrics.classification.MultilabelAUROC(ys.shape[1],average=None)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(xs, ys)\n",
    "print(f\"Train:{X_train.shape}->{y_train.shape}\")\n",
    "print(f\"Test:{X_test.shape}->{y_test.shape}\")\n",
    "# Try going bak to RidgeCV with alpha=alphas=[1e-3, 1e-2, 1e-1, 1]\n",
    "lgr = LogitRegression().fit(X_train,y_train)\n",
    "test_pred = torch.from_numpy(lgr.predict(X_test))\n",
    "scores = auroc(test_pred,y_test).numpy()\n",
    "print(\"AUROC for model from blend -> blend:\",np.mean(scores))\n",
    "idcs = np.flip(np.argsort(scores))\n",
    "print(list(zip(np.array(all_blend_notes)[idcs],scores[idcs])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
